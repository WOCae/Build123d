"""
_core.py â”€â”€ çŠ¶æ…‹ç®¡ç† / ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ / ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ / APIå‘¼ã³å‡ºã—
"""
import ast, os, re, sys, textwrap, traceback, subprocess, importlib

# â”€â”€ ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ensure_deps():
    pkgs = {'ipywidgets': 'ipywidgets', 'anthropic': 'anthropic',
            'openai': 'openai', 'google.genai': 'google-genai'}
    restart = False
    for mod, pkg in pkgs.items():
        try:
            importlib.import_module(mod)
        except ImportError:
            subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', pkg], check=True)
            restart = True
    if restart:
        try:
            from google.colab import runtime
            print('ğŸ”„ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã—ãŸã€‚å†èµ·å‹•å¾Œã«ã‚‚ã†ä¸€åº¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚')
            runtime.unassign()
        except ImportError:
            print('âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†')

# â”€â”€ çŠ¶æ…‹ç®¡ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
state = dict(
    provider        = 'anthropic',
    anthropic_key   = '', openai_key   = '', google_key   = '',
    anthropic_model = 'claude-opus-4-6',
    openai_model    = 'gpt-4o',
    google_model    = 'gemini-2.5-flash',
    history = [], last_code = '', last_err = '', last_raw = '',
)

# â”€â”€ ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SYSTEM_PROMPT = textwrap.dedent("""\
    ã‚ãªãŸã¯Build123dã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦Pythonã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

    ã€ãƒ«ãƒ¼ãƒ«ã€‘
    1. å¿…ãš `from build123d import *` ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹
    2. å½¢çŠ¶ã¯ `with BuildPart() as part:` ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£å†…ã«æ›¸ã
    3. å¯¸æ³•ã¯ã™ã¹ã¦mmå˜ä½ã§æ›¸ã
    4. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯å†’é ­ã«å¤‰æ•°ã¨ã—ã¦ã¾ã¨ã‚ã‚‹
    5. ãƒ–ãƒ¼ãƒªã‚¢ãƒ³: mode=Mode.SUBTRACTï¼ˆç©´ï¼‰/ mode=Mode.ADDï¼ˆåˆä½“ï¼‰
    6. BuildSketch ã¯ãƒã‚¹ãƒˆã—ãªã„
    7. fillet ã¯å½¢çŠ¶ç¢ºå®šå¾Œã€æœ€å¾Œã«ã‚°ãƒ­ãƒ¼ãƒãƒ«é–¢æ•°ã§å‘¼ã¶
    8. æœ€å¾Œã«å¿…ãšã“ã®2è¡Œ:
       export_step(part.part, "output/llm_output.step")
       export_stl(part.part,  "output/llm_output.stl")
    9. ã€æœ€é‡è¦ã€‘ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯(```python...```)ã®ã¿è¿”ã™ã€‚èª¬æ˜æ–‡ä¸è¦ã€‚

    ã€fillet ã®æ­£ã—ã„æ›¸ãæ–¹ã€‘
    fillet(part.edges(), radius=5)   # âœ… ã‚°ãƒ­ãƒ¼ãƒãƒ«é–¢æ•°ãƒ»part.edges() ã‚’æ¸¡ã™
    # part.fillet(...)  â† âŒ ãƒ¡ã‚½ãƒƒãƒ‰ã¯å­˜åœ¨ã—ãªã„

    ã€ç¦æ­¢ã€‘filter_by_orientation / filter_by_axis ã¯å­˜åœ¨ã—ãªã„
    ã€ä»£æ›¿ã€‘ç‰¹å®šã‚¨ãƒƒã‚¸: filter_by_position(Axis.Z, min, max)
""")

BANNED = ['os.system', 'subprocess', 'eval(', 'exec(', '__import__', 'shutil.', 'requests.', 'urllib']

# â”€â”€ ã‚³ãƒ¼ãƒ‰å‡¦ç†ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_code(text: str) -> str:
    m = re.search(r'```(?:python)?[ \t]*\n(.*?)```', text, re.DOTALL)
    if m: return m.group(1).strip()
    m = re.search(r'(from build123d import.*)', text, re.DOTALL)
    return m.group(1).strip() if m else ''

def validate_code_block(code: str, raw: str) -> tuple:
    if not code:
        return False, f'LLMãŒã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’è¿”ã—ã¾ã›ã‚“ã§ã—ãŸã€‚\nå…ˆé ­200æ–‡å­—:\n{raw[:200]}'
    if 'from build123d' not in code and 'BuildPart' not in code:
        return False, f'Build123dã®ã‚³ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\nå…ˆé ­200æ–‡å­—:\n{code[:200]}'
    return True, ''

def auto_patch(code: str) -> tuple:
    """LLMãŒã‚ˆãé–“é•ãˆã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è‡ªå‹•ä¿®æ­£"""
    patches = []
    def fix(kind, m):
        v, a = m.group(1), m.group(2)
        patches.append(f'  {v}.{kind}({a}) â†’ {kind}({v}.edges(), {a})')
        return f'{kind}({v}.edges(), {a})'
    code = re.sub(r'(\w+)\.fillet\(([^)]+)\)',  lambda m: fix('fillet',  m), code)
    code = re.sub(r'(\w+)\.chamfer\(([^)]+)\)', lambda m: fix('chamfer', m), code)
    code = re.sub(r'(fillet|chamfer)\((\w+)\.part\.edges\(\)', r'\1(\2.edges()', code)
    for bad in ['.filter_by_orientation', '.filter_by_axis', '.filter_by_type']:
        if bad in code:
            code = re.sub(re.escape(bad) + r'\([^)]*\)', '', code)
            patches.append(f'  {bad}(...) â†’ å‰Šé™¤')
    return code, patches

def run_code(code: str) -> tuple:
    code, patches = auto_patch(code)
    if patches:
        print('ğŸ”§ è‡ªå‹•ä¿®æ­£:')
        for p in patches: print(p)
    if bads := [b for b in BANNED if b in code]:
        return False, f'å®‰å…¨ãƒã‚§ãƒƒã‚¯NG: {bads}'
    try:
        ast.parse(code)
    except SyntaxError as e:
        return False, f'æ§‹æ–‡ã‚¨ãƒ©ãƒ¼: {e}'
    try:
        exec(compile(code, '<generated>', 'exec'), {'__builtins__': __builtins__})
        return True, ''
    except Exception:
        return False, traceback.format_exc()

# â”€â”€ API å‘¼ã³å‡ºã— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def call_api(user_msg: str, history: list) -> str:
    msgs = list(history) + [{'role': 'user', 'content': user_msg}]
    p = state['provider']

    if p == 'anthropic':
        import anthropic
        r = anthropic.Anthropic(api_key=state['anthropic_key']).messages.create(
            model=state['anthropic_model'], max_tokens=4096,
            system=SYSTEM_PROMPT, messages=msgs)
        return r.content[0].text

    elif p == 'openai':
        from openai import OpenAI
        r = OpenAI(api_key=state['openai_key']).chat.completions.create(
            model=state['openai_model'], max_tokens=4096,
            messages=[{'role': 'system', 'content': SYSTEM_PROMPT}] + msgs)
        return r.choices[0].message.content

    elif p == 'google':
        import time
        from google import genai
        from google.genai import types
        from google.genai.errors import APIError
        c = genai.Client(api_key=state['google_key'])
        gc = [types.Content(role='user' if m['role']=='user' else 'model',
                            parts=[types.Part(text=m['content'])]) for m in msgs[:-1]]
        contents = gc + [types.Content(role='user', parts=[types.Part(text=user_msg)])]
        for wait in [0, 15, 30]:
            if wait: time.sleep(wait)
            try:
                return c.models.generate_content(
                    model=state['google_model'], contents=contents,
                    config=types.GenerateContentConfig(
                        system_instruction=SYSTEM_PROMPT, max_output_tokens=4096)).text
            except APIError as e:
                if e.code != 429 or wait >= 30: raise
    raise ValueError('ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒæœªè¨­å®šã§ã™')

def test_connection(provider: str) -> tuple:
    try:
        if provider == 'anthropic':
            import anthropic
            anthropic.Anthropic(api_key=state['anthropic_key']).messages.create(
                model=state['anthropic_model'], max_tokens=8,
                messages=[{'role':'user','content':'hi'}])
        elif provider == 'openai':
            from openai import OpenAI
            OpenAI(api_key=state['openai_key']).chat.completions.create(
                model=state['openai_model'], max_tokens=8,
                messages=[{'role':'user','content':'hi'}])
        elif provider == 'google':
            from google import genai
            from google.genai import types
            genai.Client(api_key=state['google_key']).models.generate_content(
                model=state['google_model'], contents='hi',
                config=types.GenerateContentConfig(max_output_tokens=8))
        return True, 'æ¥ç¶šOK'
    except Exception as e:
        return False, str(e)[:120]
